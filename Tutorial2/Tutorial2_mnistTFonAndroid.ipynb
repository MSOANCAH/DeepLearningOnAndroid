{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will be solving the classical MNIST problem and deploy our solution on an android device.\n",
    "\n",
    "## Before we go ahead lets see what we are going to do\n",
    "\n",
    "- Download the data \n",
    "- Define learning rate and training step\n",
    "- create the model\n",
    "- define performance metrices\n",
    "- run the model\n",
    "- analyzing change in accuracy and loss with iteration \n",
    "\n",
    "<br></br>\n",
    "\n",
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "First of all we download the input data and investigate its nature. \n",
    "\n",
    "Running this for first time will take some time as it'll download the dataset and save in repo's root directory **MNIST_data**\n",
    "- Input is a 28x28(=784) pixels image, stored as a liner float array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "mnist = mnist_data.read_data_sets(\"../MNIST_data\", one_hot=True, validation_size=0)\n",
    "\n",
    "x_train = mnist.train.images # we will not be using these to feed in data\n",
    "y_train = mnist.train.labels # instead we will be using next_batch function to train in batches\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print ('We have '+str(x_train.shape[0])+' training examples in dataset')\n",
    "print ('We have '+str(x_train.shape[1])+' feature points(basically pixels) in each input example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_NAME = 'Tutorial2'\n",
    "MODEL_NAME = 'mnistTFonAndroid'\n",
    "SAVED_MODEL_PATH = '../' + TUTORIAL_NAME+'_Saved_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and Training step\n",
    "\n",
    "**OK. This section has a great deal of learning so those who are new to deep learning kindly read carefully**\n",
    "\n",
    "Lets lay down how do Nerual nets work\n",
    "\n",
    "- We create computation nodes with some weights associated to them. \n",
    "- These weights are used to create predictions from the input we give in\n",
    "- If prediction is correct that's good, ELSE WE ADJUST THOSE WEIGHTS TO IMPROVE PREDICTION ACCURACY\n",
    "- To aid in adjusting those weights we create some performance parameters like ACCURACY and LOSS\n",
    "\n",
    "\n",
    "You remember when I introduced Parameters(weights) I said they have some magic values. That magic value is obtained by training our model. Training our model basically is \n",
    "- We initialize the Parameters with random value \n",
    "- We feed in our input and check if model gives correct output\n",
    "- If no, we adjust the parameters on basis of how wrong the prediction was\n",
    "- We repeat this for all the example several time, doing this repeatedly \n",
    "\n",
    "How many times we feed the whole dataset into model is **TRAIN_STEPS**\n",
    "\n",
    "In this how much to adjust the weights is determined by **LEARNING_RATE**\n",
    "\n",
    "Learning rate is the quantum of step you take in order to reach the optimal accuracy point\n",
    "\n",
    "<img src=\"../images/t2_1_learning_rate.jpeg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "(When you run this example below you'll observe a large learning rate is ok in starting but soon it becomes ineffective to increase accuracy beyond a certain point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "Defining our network, a single node network with two input nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784], name='modelInput')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784,10]), name='modelWeights')\n",
    "b = tf.Variable(tf.zeros([10]), name='modelBias')\n",
    "Y = tf.nn.softmax(tf.matmul(X,W) + b, name='modelOutput')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrices to learn and judge our model\n",
    "\n",
    "See the training variable below , It takes in LEARNING_RATE and will adjust the weights on basis of cross_entropy we calculate. Cross_entropy is just how wrong our prediction was on a lograthmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention here\n",
    "\n",
    "In last tutorial we manually converted a variable and deployed on android. Here we will use the freeze_graph api provided by google.\n",
    "\n",
    "Before that\n",
    "- During training our weights W and b will learn some value. We will periodically save those learned parameters onto harddisk\n",
    "- Learned variables are saved as checkpoint file **.ckpt** using the tf.train.Saver() API.\n",
    "- code below will be saving check point files for you\n",
    "```python\n",
    "    if i%500 == 0:\n",
    "        out = saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt', global_step=i)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model\n",
    "Below is the code where our model is trained on the input data. Once you run it you will see that accuracy increases till a certain point (roughly around 500 steps) after which we did  not see any improvements.\n",
    "\n",
    "- our maximum accuracy is where blue line meets the curve beyond which it bounces back \n",
    "- to go into further into purple region in need to decrease the learning rate\n",
    "\n",
    "<img src=\"../images/t2_2_lr_explain.jpeg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(TRAIN_STEPS+1):\n",
    "    sess.run(training, feed_dict={X: x_train, Y_: y_train})\n",
    "    if i%100 == 0:\n",
    "        print('Training Step:' + str(i) + \n",
    "              '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={X: x_test, Y_: y_test})) + \n",
    "              '  Loss = ' + str(sess.run(cross_entropy, {X: x_train, Y_: y_train}))\n",
    "             )\n",
    "    if i%500 == 0:\n",
    "        out = saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt', global_step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save our graph defination as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pbtxt')\n",
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pb',as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our model defination in a .pb file and values of variables learned in ckpt file.\n",
    "Our next task is to merge the .pb file and .ckpt file into a single .pb file and freeze all the variable nodes into constant nodes.\n",
    "\n",
    "Remember the input checkpoint file shoud be the latest one saved, kindly go and check the Tutorial2_Saved_model folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "# Freeze the graph\n",
    "input_graph = SAVED_MODEL_PATH+MODEL_NAME+'.pb'\n",
    "input_saver = \"\"\n",
    "input_binary = True\n",
    "input_checkpoint = SAVED_MODEL_PATH+MODEL_NAME+'.ckpt-'+str(TRAIN_STEPS)\n",
    "output_node_names = 'modelOutput'\n",
    "restore_op_name = 'save/restore_all'\n",
    "filename_tensor_name = 'save/Const:0'\n",
    "output_graph = SAVED_MODEL_PATH+'frozen_'+MODEL_NAME+'.pb'\n",
    "clear_devices = True\n",
    "initializer_nodes = \"\"\n",
    "variable_names_blacklist = \"\"\n",
    "\n",
    "freeze_graph.freeze_graph(\n",
    "    input_graph,\n",
    "    input_saver,\n",
    "    input_binary,\n",
    "    input_checkpoint,\n",
    "    output_node_names,\n",
    "    restore_op_name,\n",
    "    filename_tensor_name,\n",
    "    output_graph,\n",
    "    clear_devices,\n",
    "    initializer_nodes,\n",
    "    variable_names_blacklist\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have executed all the code above you will find \n",
    "- **mnistTFonAndroid.pbtxt** file, open it see your graph defination there\n",
    "- **frozen_mnistTFonAndroid.pb** file , which we have to copy to our assets folder in android app, change the name by deleting the underscore in _frozen_mnistTFonAndroid.pb in **.MNISTActivity.java** and run the app.\n",
    "\n",
    "Complete code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: ' + tf.__version__)\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "mnist = mnist_data.read_data_sets(\"../MNIST_data\", one_hot=True, validation_size=0)\n",
    "\n",
    "x_train = mnist.train.images # we will not be using these to feed in data\n",
    "y_train = mnist.train.labels # instead we will be using next_batch function to train in batches\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "print ('We have '+str(x_train.shape[0])+' training examples in dataset')\n",
    "print ('We have '+str(x_train.shape[1])+' feature points(basically pixels) in each input example')\n",
    "\n",
    "\n",
    "TUTORIAL_NAME = 'Tutorial2'\n",
    "MODEL_NAME = 'mnistTFonAndroid'\n",
    "SAVED_MODEL_PATH = '../' + TUTORIAL_NAME+'_Saved_model/'\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "TRAIN_STEPS = 2000\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784], name='modelInput')\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784,10]), name='modelWeights')\n",
    "b = tf.Variable(tf.zeros([10]), name='modelBias')\n",
    "Y = tf.nn.softmax(tf.matmul(X,W) + b, name='modelOutput')\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "for i in range(TRAIN_STEPS+1):\n",
    "    sess.run(training, feed_dict={X: x_train, Y_: y_train})\n",
    "    if i%100 == 0:\n",
    "        print('Training Step:' + str(i) + \n",
    "              '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={X: x_test, Y_: y_test})) + \n",
    "              '  Loss = ' + str(sess.run(cross_entropy, {X: x_train, Y_: y_train}))\n",
    "             )\n",
    "    if i%500 == 0:\n",
    "        out = saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt', global_step=i)\n",
    "           \n",
    "        \n",
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pbtxt')\n",
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pb',as_text=False)\n",
    "\n",
    "\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "# Freeze the graph\n",
    "input_graph = SAVED_MODEL_PATH+MODEL_NAME+'.pb'\n",
    "input_saver = \"\"\n",
    "input_binary = True\n",
    "input_checkpoint = SAVED_MODEL_PATH+MODEL_NAME+'.ckpt-'+str(TRAIN_STEPS)\n",
    "output_node_names = 'modelOutput'\n",
    "restore_op_name = 'save/restore_all'\n",
    "filename_tensor_name = 'save/Const:0'\n",
    "output_graph = SAVED_MODEL_PATH+'frozen_'+MODEL_NAME+'.pb'\n",
    "clear_devices = True\n",
    "initializer_nodes = \"\"\n",
    "variable_names_blacklist = \"\"\n",
    "\n",
    "freeze_graph.freeze_graph(\n",
    "    input_graph,\n",
    "    input_saver,\n",
    "    input_binary,\n",
    "    input_checkpoint,\n",
    "    output_node_names,\n",
    "    restore_op_name,\n",
    "    filename_tensor_name,\n",
    "    output_graph,\n",
    "    clear_devices,\n",
    "    initializer_nodes,\n",
    "    variable_names_blacklist\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
