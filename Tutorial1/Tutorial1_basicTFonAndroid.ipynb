{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_NAME = 'Tutorial1'\n",
    "MODEL_NAME = 'basicTFonAndroid'\n",
    "SAVED_MODEL_PATH = '../' + TUTORIAL_NAME+'_Saved_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=[1], name='modelInputA') # input a\n",
    "B = tf.placeholder(tf.float32, shape=[1], name='modelInputB') # input b\n",
    "\n",
    "# A tensorflow variable not used anywhere in this model\n",
    "W = tf.Variable(tf.zeros(shape=[1]), dtype=tf.float32, name='W') # weights\n",
    "\n",
    "# sum of two matrices element-wise, in our case two numbers in \n",
    "AB = tf.add(A, B, name='modelOutputAB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(AB,{A:[2],B:[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the graph\n",
    "\n",
    "input_graph = SAVED_MODEL_PATH+MODEL_NAME+'.pbtxt'\n",
    "input_saver = \"\"\n",
    "input_binary = False\n",
    "input_checkpoint = SAVED_MODEL_PATH+MODEL_NAME+'.ckpt'\n",
    "output_node_names = 'modelOutputAB'\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_graph = SAVED_MODEL_PATH+'frozen_'+MODEL_NAME+'.pb'\n",
    "clear_devices = True\n",
    "initializer_nodes = \"\"\n",
    "variable_names_blacklist=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_graph.freeze_graph(input_graph,\n",
    "                 input_saver,\n",
    "                 input_binary,\n",
    "                 input_checkpoint,\n",
    "                 output_node_names,\n",
    "                 restore_op_name,\n",
    "                 filename_tensor_name,\n",
    "                 output_graph,\n",
    "                 clear_devices,\n",
    "                 initializer_nodes,\n",
    "                 variable_names_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code is generating empty optimized frozen graph, need to debug\n",
    "# for time being use simple frozen graph generated above\n",
    "input_node_names = ['modelInputA','modelInputB']\n",
    "output_frozen_graph_name = SAVED_MODEL_PATH+'frozen_'+MODEL_NAME+'.pb'\n",
    "output_optimized_graph_name = SAVED_MODEL_PATH+'optimized_'+MODEL_NAME+'.pb'\n",
    "\n",
    "from google.protobuf import text_format\n",
    "\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "input_graph_def = graph_pb2.GraphDef()\n",
    "\n",
    "with tf.gfile.Open(output_frozen_graph_name, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    input_graph_def.ParseFromString(data)\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "    input_graph_def,\n",
    "    [\"modelInputA\",\"modelInputB\"], # an array of the input node(s)\n",
    "    ['modelOutputAB'], # an array of output nodes\n",
    "    tf.float32.as_datatype_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized graph\n",
    "f = tf.gfile.FastGFile(output_optimized_graph_name, \"w\")\n",
    "f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
